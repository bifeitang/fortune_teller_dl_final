{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DL_Final_Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowing when to look"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM part "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AdaptiveAttentionLstm(nn.Module):\n",
    "    def __init__(self, opt, maxout=True):\n",
    "        self.att_feat_size = opt.att_feat_size\n",
    "        self.dropout = opt.dropout  \n",
    "        self.maxout = opt.maxout\n",
    "        self.training = opt.training\n",
    "        self.input_size_L = opt.input_size_L\n",
    "        \n",
    "        #Build the LSTM network\n",
    "        self.w2h = nn.Linear(self.input_encoding_size, (4+(use_maxout==True)) * self.rnn_size)\n",
    "        self.v2h = nn.Linear(self.rnn_size, (4+(use_maxout==True)) * self.rnn_size)\n",
    "        \n",
    "        self.i2h = nn.ModuleList([nn.Linear(self.rnn_size, (4+(use_maxout==True)) * self.rnn_size) for _ in range(self.num_layers - 1)])\n",
    "        self.h2h = nn.ModuleList([nn.Linear(self.rnn_size, (4+(use_maxout==True)) * self.rnn_size) for _ in range(self.num_layers)])\n",
    "        \n",
    "        \n",
    "            \n",
    "    def forward(self, x_t, state):\n",
    "        # hidden states of all layers\n",
    "        hidden_states = []\n",
    "        # cell states of all layers\n",
    "        cell_states = []\n",
    "        for layer in range(self.num_layers):\n",
    "            # hidden state of previous timestamp\n",
    "            prev_h = state[0][layer]\n",
    "            # cell state of previous timestamp\n",
    "            prev_c = state[1][layer]\n",
    "            \n",
    "            if layer == 0: \n",
    "                x = x_t\n",
    "                i2h = self.w2h(x)\n",
    "            else:\n",
    "                x = hidden_states[-1]\n",
    "                x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "                i2h = self.i2h[layer-1](x)\n",
    "            \n",
    "            all_input_sums = i2h + self.h2h[layer](prev_h)\n",
    "        \n",
    "\n",
    "local LSTM = {}\n",
    "function LSTM.lstm(input_size, rnn_size, n, dropout)\n",
    "    dropout = dropout or 0 \n",
    "\n",
    "# there will be 2*n+1 inputs\n",
    "    local inputs = {}\n",
    "    table.insert(inputs, nn.Identity()()) # indices giving the sequence of symbols\n",
    "    table.insert(inputs, nn.Identity()()) # indices giving the image feature  \n",
    "    for L = 1,n:\n",
    "        table.insert(inputs, nn.Identity()()) # prev_c[L]\n",
    "        table.insert(inputs, nn.Identity()()) # prev_h[L]\n",
    "\n",
    "    local img_fc = inputs[2]\n",
    "\n",
    "    local x, input_size_L, i2h, fake_region, atten_region\n",
    "    local outputs = {}\n",
    "    for L = 1,n do\n",
    "        # c,h from previos timesteps\n",
    "        local prev_h = inputs[L*2+2]\n",
    "        local prev_c = inputs[L*2+1]\n",
    "        # the input to this layer\n",
    "        if L == 1 then \n",
    "            x = inputs[1]\n",
    "            input_size_L = input_size\n",
    "            local w2h = nn.Linear(input_size_L, 4 * rnn_size)(x):annotate{name='t2h_'..L}\n",
    "            local v2h = nn.Linear(input_size_L, 4 * rnn_size)(img_fc):annotate{name='v2h_'..L}\n",
    "            i2h = nn.CAddTable()({w2h, v2h})\n",
    "        else\n",
    "            x = outputs[(L-1)*2]\n",
    "            if dropout > 0 then x = nn.Dropout(dropout)(x):annotate{name='drop_' .. L} end -- apply dropout, if any\n",
    "            input_size_L = rnn_size\n",
    "            i2h = nn.Linear(input_size_L, 4 * rnn_size)(x):annotate{name='i2h_'..L}\n",
    "        end\n",
    "\n",
    "        local h2h = nn.Linear(rnn_size, 4 * rnn_size)(prev_h):annotate{name='h2h_'..L}\n",
    "        local all_input_sums = nn.CAddTable()({i2h, h2h})\n",
    "\n",
    "        local reshaped = nn.Reshape(4, rnn_size)(all_input_sums)\n",
    "        local n1, n2, n3, n4 = nn.SplitTable(2)(reshaped):split(4)\n",
    "        # decode the gates\n",
    "        local in_gate = nn.Sigmoid()(n1)\n",
    "        local forget_gate = nn.Sigmoid()(n2)\n",
    "        local out_gate = nn.Sigmoid()(n3)\n",
    "        # decode the write inputs\n",
    "        local in_transform = nn.Tanh()(n4)\n",
    "        # perform the LSTM update\n",
    "        local next_c           = nn.CAddTable()({\n",
    "            nn.CMulTable()({forget_gate, prev_c}),\n",
    "            nn.CMulTable()({in_gate,     in_transform})\n",
    "          })\n",
    "\n",
    "        local tanh_nex_c = nn.Tanh()(next_c)\n",
    "        # gated cells form the output\n",
    "        local next_h = nn.CMulTable()({out_gate,tanh_nex_c})\n",
    "        if L == n then\n",
    "            if L==1 then\n",
    "                local w2h = nn.Linear(input_size_L, 1 * rnn_size)(x)\n",
    "                local v2h = nn.Linear(input_size_L, 1 * rnn_size)(img_fc) \n",
    "                i2h = nn.CAddTable()({w2h, v2h})\n",
    "            else\n",
    "                i2h = nn.Linear(input_size_L, rnn_size)(x)\n",
    "            end      \n",
    "            local h2h = nn.Linear(rnn_size, rnn_size)(prev_h)\n",
    "            local n5 = nn.CAddTable()({i2h, h2h})\n",
    "\n",
    "            fake_region = nn.CMulTable()({nn.Sigmoid()(n5), tanh_nex_c})\n",
    "        end\n",
    "\n",
    "        table.insert(outputs, next_c)\n",
    "        table.insert(outputs, next_h)\n",
    "    end\n",
    "    # set up the decoder\n",
    "    local top_h = nn.Identity()(outputs[#outputs])\n",
    "    if dropout > 0 then top_h = nn.Dropout(dropout)(top_h) end\n",
    "    if dropout > 0 then fake_region = nn.Dropout(dropout)(fake_region) end\n",
    "\n",
    "    table.insert(outputs, top_h)\n",
    "    table.insert(outputs, fake_region)\n",
    "    return nn.gModule(inputs, outputs)\n",
    "end\n",
    "\n",
    "return LSTM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive attention model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveAttention(CaptionModel):\n",
    "    def __init__(self, opt):\n",
    "        super(AdaptiveAttention, self).__init__()\n",
    "        self.vocab_size = opt.vocab_size\n",
    "        self.input_encoding_size = opt.input_encoding_size       # 512\n",
    "        self.rnn_size = opt.rnn_size       # 512\n",
    "        self.num_layers = opt.num_layers   # 1\n",
    "        self.dropout = opt.dropout         # 0.5\n",
    "        self.seq_length = opt.seq_length   # max length for the caption 20\n",
    "        self.fc_size = opt.fc_size         # 2048\n",
    "        self.conv_size = opt.conv_size     # 2048\n",
    "        self.hidden_size = opt.hidden_size #\n",
    "        \n",
    "        self.image_embedding = \n",
    "            \n",
    "            \n",
    "            \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
